# üí≥ Credit Risk MLOps - German Credit Dataset

\<div align="center"\>

**MLOps Team 46 - Proyecto de Clasificaci√≥n de Riesgo Crediticio**

[](https://www.python.org/downloads/)
[](https://mlflow.org/)
[](https://dvc.org/)
[](https://aws.amazon.com/s3/)
[](https://streamlit.io/)

[](https://www.google.com/search?q=%23-uso-del-pipeline-automatizado)
[](https://www.google.com/search?q=%23-instalaci%C3%B3n)

\</div\>

-----

## üìã Tabla de Contenidos

  - [Sobre el Proyecto](https://www.google.com/search?q=%23-sobre-el-proyecto)
  - [Informaci√≥n Acad√©mica](https://www.google.com/search?q=%23-informaci%C3%B3n-acad%C3%A9mica)
  - [Arquitectura del Pipeline](https://www.google.com/search?q=%23-arquitectura-del-pipeline)
  - [Estructura del Proyecto](https://www.google.com/search?q=%23-estructura-del-proyecto)
  - [Requisitos Previos](https://www.google.com/search?q=%23-requisitos-previos)
  - [Instalaci√≥n](https://www.google.com/search?q=%23-instalaci%C3%B3n)
  - [Uso](https://www.google.com/search?q=%23-uso)
      - [Uso del Pipeline Automatizado](https://www.google.com/search?q=%23-uso-del-pipeline-automatizado)
      - [Tracking de Experimentos con MLflow](https://www.google.com/search?q=%23-tracking-de-experimentos-con-mlflow)
      - [Ejecuci√≥n Manual de Etapas (DVC)](https://www.google.com/search?q=%23-ejecuci%C3%B3n-manual-de-etapas-dvc)
      - [Aplicaci√≥n de Predicci√≥n (Streamlit)](https://www.google.com/search?q=%23-aplicaci%C3%B3n-de-predicci%C3%B3n-streamlit)
  - [Flujo de Contribuci√≥n](https://www.google.com/search?q=%23-flujo-de-contribuci%C3%B3n)
  - [Equipo](https://www.google.com/search?q=%23-equipo)

-----

## üéØ Sobre el Proyecto

Este repositorio contiene la implementaci√≥n completa de un sistema MLOps para la clasificaci√≥n de riesgo crediticio utilizando el dataset "German Credit". El proyecto integra las mejores pr√°cticas de la industria para asegurar la reproducibilidad y la colaboraci√≥n.

  - üìä **Versionado de datos y modelos** con DVC.
  - üîÑ **Pipelines reproducibles** con DVC que automatizan la limpieza, el an√°lisis (EDA) y el entrenamiento.
  - üìà **Seguimiento de experimentos** con MLflow para registrar m√©tricas, par√°metros y artefactos.
  - ‚òÅÔ∏è **Almacenamiento en la nube** con AWS S3 para los artefactos de DVC.
  - ü§ñ **Entrenamiento de un modelo XGBoost**, incluyendo interpretabilidad con SHAP.
  - üí° **Aplicaci√≥n interactiva** con Streamlit para realizar predicciones en tiempo real.
  - üèóÔ∏è **Estructura de proyecto modular** y escalable.

-----

## üìò Informaci√≥n Acad√©mica

**Instituto Tecnol√≥gico y de Estudios Superiores de Monterrey** *Maestr√≠a en Inteligencia Artificial Aplicada (MNA)*

  - **Curso:** Operaciones de Aprendizaje Autom√°tico (MLOps)
  - **Periodo:** Septiembre ‚Äì Diciembre 2025
  - **Equipo:** N¬∞ 46

### üë®‚Äçüè´ Profesores

| Rol | Nombre |
|---|---|
| Titular | Dr. Gerardo Rodr√≠guez Hern√°ndez |
| Titular | Mtro. Ricardo Valdez Hern√°ndez |
| Asistente | Mtra. Mar√≠a Mylen Trevi√±o Elizondo |
| Tutor | Dr. Jos√© Carlos Soto Monterrubio |

-----

## üèóÔ∏è Arquitectura del Pipeline

```mermaid
flowchart TD
    subgraph Git Repository
        A[params.yaml]
        B[german_credit_ml/]
        C[dvc.yaml]
    end

    subgraph DVC Pipeline
        D[raw_data: german_credit_modified.csv] -->|clean.py| E[clean_data: german_credit_clean.csv]
        E -->|eda.py| F[plots_eda: reports/figures/eda/]
        E -->|train.py| G[model: xgboost_model.pkl]
        E -->|train.py| H[plots_train: reports/figures/training/]
        E -->|train.py| I[metrics: metrics.json]
    end
    
    J[‚òÅÔ∏è AWS S3 Bucket]
    K[üñ•Ô∏è MLflow UI]
    
    G & H & I -- DVC Versioning --> J
    F -- DVC Versioning --> J
    E -- DVC Versioning --> J
    
    G & H & I -- MLflow Tracking --> K

    style A fill:#e1f5ff
    style B fill:#e1f5ff
    style C fill:#e1f5ff
    style J fill:#fff4e1
    style K fill:#f3e5f5
```

-----

## üìÅ Estructura del Proyecto

```
‚îú‚îÄ‚îÄ README.md              <- Este archivo
‚îú‚îÄ‚îÄ params.yaml            <- Par√°metros y rutas del pipeline
‚îú‚îÄ‚îÄ dvc.yaml               <- Definici√≥n de las etapas del pipeline DVC
‚îú‚îÄ‚îÄ requirements.txt       <- Dependencias del proyecto
‚îú‚îÄ‚îÄ run_pipeline.sh        <- Script para ejecutar el pipeline completo
‚îÇ
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ processed          <- Datasets limpios para modelado (Salida de DVC)
‚îÇ   ‚îî‚îÄ‚îÄ raw                <- Datos originales inmutables (Rastreado por DVC)
‚îÇ
‚îú‚îÄ‚îÄ models                 <- Modelos entrenados y serializados (Salida de DVC)
‚îÇ
‚îú‚îÄ‚îÄ notebooks              <- Jupyter notebooks para exploraci√≥n y prototipado
‚îÇ
‚îú‚îÄ‚îÄ reports
‚îÇ   ‚îú‚îÄ‚îÄ figures            <- Gr√°ficas generadas por el pipeline (Salida de DVC)
‚îÇ   ‚îî‚îÄ‚îÄ metrics.json       <- M√©tricas de rendimiento del modelo (Salida de DVC)
‚îÇ
‚îú‚îÄ‚îÄ german_credit_ml/      <- C√≥digo fuente del proyecto (m√≥dulo Python)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ clean.py           <- Script de limpieza de datos
‚îÇ   ‚îú‚îÄ‚îÄ eda.py             <- Script de an√°lisis exploratorio
‚îÇ   ‚îî‚îÄ‚îÄ modeling
‚îÇ       ‚îú‚îÄ‚îÄ train.py       <- Script de entrenamiento de modelos
‚îÇ       ‚îî‚îÄ‚îÄ predict.py     <- L√≥gica de predicci√≥n
‚îÇ
‚îú‚îÄ‚îÄ predict_app.py         <- Aplicaci√≥n interactiva con Streamlit
‚îÇ
‚îú‚îÄ‚îÄ .dvc/                  <- Configuraci√≥n de DVC
‚îî‚îÄ‚îÄ mlruns/                <- Carpeta de tracking de experimentos de MLflow (ignorada por Git)
```

-----

## üõ† Requisitos Previos

  - **Python 3.9+**
  - **Git**
  - **Conda** para gesti√≥n de entornos
  - **Credenciales de AWS** configuradas para acceder a S3.

-----

## üöÄ Instalaci√≥n

1.  **Clonar el repositorio:**

    ```bash
    git clone https://github.com/jmtoral/mna-mlops-team46.git
    cd mna-mlops-team46
    ```

2.  **Configurar entorno de Conda:**
    Abre **Anaconda Prompt** o **Git Bash** (previamente configurado con `conda init bash`).

    ```bash
    # Activa el entorno 'mlops'
    conda activate mlops

    # Si no existe, cr√©alo primero: conda create --name mlops python=3.9

    # Instala todas las dependencias
    pip install -r requirements.txt
    ```

3.  **Configurar DVC con AWS S3:**
    Necesitar√°s las credenciales de AWS.

    ```bash
    # Configura tus credenciales (reemplaza los placeholders)
    dvc remote modify --local origin access_key_id "TU_ACCESS_KEY_ID"
    dvc remote modify --local origin secret_access_key "TU_SECRET_ACCESS_KEY"
    ```

4.  **Descargar datos y modelos:**
    Este comando descarga la √∫ltima versi√≥n de todos los artefactos desde S3.

    ```bash
    dvc pull
    ```

-----

## üíª Uso

### ‚ñ∂Ô∏è Uso del Pipeline Automatizado

El script `run_pipeline.sh` es la forma principal de interactuar con el proyecto. Detecta cambios y ejecuta las etapas necesarias, versionando y subiendo los resultados.

```bash
# Ejecutar el pipeline completo
bash run_pipeline.sh
```

  - **Si modificas c√≥digo** (ej. `train.py`), solo ejecuta el script.
  - **Si actualizas datos crudos**, primero haz `dvc add data/raw/tu_archivo.csv` y luego ejecuta el script.

### üìà Tracking de Experimentos con MLflow

Para visualizar y comparar tus experimentos de entrenamiento:

1.  **Inicia el servidor de MLflow:**
    ```bash
    mlflow ui
    ```
2.  **Abre tu navegador** en `http://localhost:5000`.

### ‚õìÔ∏è Ejecuci√≥n Manual de Etapas (DVC)

Si deseas ejecutar todo el pipeline sin los commits autom√°ticos:

```bash
dvc repro
```

Para ver las m√©tricas del √∫ltimo modelo entrenado:

```bash
dvc metrics show
```

### üí° Aplicaci√≥n de Predicci√≥n (Streamlit)

Para interactuar con el modelo y realizar predicciones en tiempo real:

1.  Aseg√∫rate de tener el √∫ltimo modelo (`dvc pull` o `dvc repro`).
2.  Ejecuta la aplicaci√≥n:
    ```bash
    streamlit run predict_app.py
    ```
3.  **Abre tu navegador** en la `Local URL` que te indique la terminal (ej. `http://localhost:8501`).

-----

## ü§ù Flujo de Contribuci√≥n

1.  **Sincroniza tu repositorio:**

    ```bash
    git pull
    dvc pull
    ```

2.  **Crea una nueva rama:**

    ```bash
    git checkout -b feat/nombre-descriptivo
    ```

3.  **Realiza cambios y ejecuta el pipeline:**

    ```bash
    # (Edita c√≥digo, actualiza datos, etc.)
    bash run_pipeline.sh
    ```

4.  **Verifica los resultados** en MLflow y los archivos generados.

5.  **Sube tus cambios** (el script ya se encarga de los `commits` y `push`).
    Si hiciste cambios adicionales (ej. en `README.md`), haz commit manualmente.

6.  **Crea un Pull Request** en GitHub a la rama `master`.

-----

## üë• Equipo

| Integrante | Matr√≠cula | Rol |
|---|---|---|
| Jes√∫s Alberto Jim√©nez Ramos | `A01796903` | üìä Data Engineer |
| M√≥nica Mar√≠a Del Rivero S√°nchez | `A01362368` | üë©‚Äçüî¨ Data Scientist |
| Montserrat Gayt√°n Morales | `A01332220` | üíª Software Engineer |
| Jos√© Manuel Toral Cruz | `A01122243` | ü§ñ ML Engineer |
| Jeanette Rios Martinez | `A01688888` | üõ†Ô∏è SRE / DevOps |

-----

\<div align="center"\>
Desarrollado con ‚ù§Ô∏è por el Equipo 46 | MNA
\</div\>